{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project – Predicting House Price\n",
    "## Members: Shiqi Wang, Tao Tao, Ying Ben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purchasing a house is a major milestone that tops many people's lifetime to-do lists, and possibly their lists of financial fears too. When people tend to buy a house, there are too many elements to consider, e.g., the neighborhood, and the area. However, among these elements, house price is probably the one which nearly everyone cares the most about. There is a project in the Kaggle targeting such a problem, i.e., House Prices: Advanced Regression Techniques. In this project, our team will make a prediction of the house prices based on lots of features and the knowledge learnt from Machine Learning course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 79 explanatory variables describing almost every aspect of residential home in Ames, Iowa. \n",
    "\n",
    "Our goal is to predict price of each home. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous work has indicated that the location of houses are important when predicting house price, and Steven C. Bourassa, Eva Cantoni and Martin Hoesli had developed spatial statistical models to improve the performance of conventional models, such as OLS model [1]. We will try to apply their models in our current work because our dataset has some spatial attributesand we hope it will have good performance.\n",
    "\n",
    "Besides, we will use a hybrid regression model to predict house price. This idea is based on the work of Sifei Lu, who presented a regression method combined by Gradient boosting regression model and Lasso for house price regression [2]. According to the conclusion, this hybrid model has low rmse in their house dataset, so we will see whether this idea can perform well in our dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Detailed problem \n",
    "\n",
    "### Data Overview\n",
    "    - Large number of features (80 features).\n",
    "    - Most data is categorical data which illustrates condition of houses.\n",
    "    - Have “NA” values in many features.\n",
    "### Problems\n",
    "    - Lots of features are needed to process.\n",
    "    - More features will be generated after transforming categorical data to numerical data.\n",
    "    - The large amount of features may influence the efficiency of models and be difficult to interpret.\n",
    "    - How to deal with “NA” values properly.\n",
    "\n",
    "### Objective:\n",
    "    - Reduce the number features by selecting or combining  proper features.\n",
    "    - How to reduce features:\n",
    "        Looking the distribution and variance of features.\n",
    "        Looking the coefficient between features and target.\n",
    "        By experience (e.g. business logic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Approaches\n",
    "### 5-1 train-data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities      ...       ScreenPorch PoolArea PoolQC Fence  \\\n",
      "0         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
      "1         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
      "2         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
      "3         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
      "4         Lvl    AllPub      ...                 0        0    NaN   NaN   \n",
      "\n",
      "  MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
      "0         NaN       0      2    2008        WD         Normal  \n",
      "1         NaN       0      5    2007        WD         Normal  \n",
      "2         NaN       0      9    2008        WD         Normal  \n",
      "3         NaN       0      2    2006        WD        Abnorml  \n",
      "4         NaN       0     12    2008        WD         Normal  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "0    12.247699\n",
      "1    12.109016\n",
      "2    12.317171\n",
      "3    11.849405\n",
      "4    12.429220\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Read Data\n",
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "# Extract data and target\n",
    "target = np.log1p(dataset['SalePrice'])\n",
    "data = dataset.drop(columns='SalePrice')\n",
    "print(data[0:5])\n",
    "print(target[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SaleCondition', 'SaleType', 'WoodDeckSF', 'MiscFeature', 'MiscVal', 'Fence', 'PoolArea', 'PoolQC', 'ScreenPorch', '3SsnPorch', 'EnclosedPorch', 'PavedDrive', 'GarageCond', 'GarageQual', 'GarageYrBlt', 'Foundation', 'Functional', 'KitchenAbvGr', 'BsmtHalfBath', 'LowQualFinSF', 'Electrical', 'CentralAir', 'Heating', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtCond', 'ExterCond', 'Exterior1st', 'Exterior2nd', 'RoofMatl', 'RoofStyle', 'BldgType', 'Condition1', 'Condition2', 'LandSlope', 'Utilities', 'LandContour', 'Alley', 'Street', 'LotConfig', 'MSZoning', 'MSSubClass', 'Id', 'MasVnrType']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop features, features have been selected in a file\n",
    "col_list = []\n",
    "f = open(\"FeatureEngineering.txt\", \"r\")\n",
    "line = f.readline()\n",
    "for line in f:\n",
    "    if line != \"\\n\":\n",
    "        col_list.append(line.split('\\t')[0])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "col_list.append(\"MasVnrType\")\n",
    "# Temporarily drop Neighborhood for we have not had any insight now\n",
    "# .append(\"Neighborhood\")\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotFrontage  LotArea LotShape Neighborhood HouseStyle  OverallQual  \\\n",
      "1         80.0     9600      Reg      Veenker     1Story            6   \n",
      "2         68.0    11250      IR1      CollgCr     2Story            7   \n",
      "3         60.0     9550      IR1      Crawfor     2Story            7   \n",
      "4         84.0    14260      IR1      NoRidge     2Story            8   \n",
      "\n",
      "   OverallCond  YearBuilt  YearRemodAdd  MasVnrArea   ...   TotRmsAbvGrd  \\\n",
      "1            8       1976          1976         0.0   ...              6   \n",
      "2            5       2001          2002       162.0   ...              6   \n",
      "3            5       1915          1970         0.0   ...              7   \n",
      "4            5       2000          2000       350.0   ...              9   \n",
      "\n",
      "  Fireplaces FireplaceQu GarageType  GarageFinish  GarageCars  GarageArea  \\\n",
      "1          1          TA     Attchd           RFn           2         460   \n",
      "2          1          TA     Attchd           RFn           2         608   \n",
      "3          1          Gd     Detchd           Unf           3         642   \n",
      "4          1          TA     Attchd           RFn           3         836   \n",
      "\n",
      "  OpenPorchSF  MoSold  YrSold  \n",
      "1           0       5    2007  \n",
      "2          42       9    2008  \n",
      "3          35       2    2006  \n",
      "4          84      12    2008  \n",
      "\n",
      "[4 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(columns = col_list)\n",
    "print(data[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotFrontage  LotArea LotShape Neighborhood HouseStyle  OverallQual  \\\n",
      "1         80.0     9600        3      Veenker     1Story            6   \n",
      "2         68.0    11250        2      CollgCr     2Story            7   \n",
      "3         60.0     9550        2      Crawfor     2Story            7   \n",
      "4         84.0    14260        2      NoRidge     2Story            8   \n",
      "\n",
      "   OverallCond  YearBuilt  YearRemodAdd  MasVnrArea   ...   TotRmsAbvGrd  \\\n",
      "1            8       1976          1976         0.0   ...              6   \n",
      "2            5       2001          2002       162.0   ...              6   \n",
      "3            5       1915          1970         0.0   ...              7   \n",
      "4            5       2000          2000       350.0   ...              9   \n",
      "\n",
      "  Fireplaces FireplaceQu GarageType  GarageFinish  GarageCars  GarageArea  \\\n",
      "1          1           3     Attchd             2           2         460   \n",
      "2          1           3     Attchd             2           2         608   \n",
      "3          1           4     Detchd             1           3         642   \n",
      "4          1           3     Attchd             2           3         836   \n",
      "\n",
      "  OpenPorchSF  MoSold  YrSold  \n",
      "1           0       5    2007  \n",
      "2          42       9    2008  \n",
      "3          35       2    2006  \n",
      "4          84      12    2008  \n",
      "\n",
      "[4 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "# Label Encoding\n",
    "def labelEncode(column, score_set):\n",
    "    na_table = column.isnull()\n",
    "    for i in range(0, len(column)):\n",
    "        for j in range(0, len(score_set)):\n",
    "            if column[i] == score_set[j]:\n",
    "                column[i] = j\n",
    "                break\n",
    "            if na_table[i] == True:\n",
    "                column[i] = 0\n",
    "\n",
    "# LotShape\n",
    "score_set = [\"IR3\", \"IR2\", \"IR1\", \"Reg\"]\n",
    "labelEncode(data[\"LotShape\"], score_set)\n",
    "# ExterQual\n",
    "score_set = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "labelEncode(data[\"ExterQual\"], score_set)\n",
    "# BsmtQual\n",
    "score_set = [\"NA\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "labelEncode(data[\"BsmtQual\"], score_set)\n",
    "# BsmtExposure\n",
    "score_set = [\"NA\", \"No\", \"Mn\", \"Av\", \"Gd\"]\n",
    "labelEncode(data[\"BsmtExposure\"], score_set)\n",
    "# BsmtFinType1\n",
    "score_set = [\"NA\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"]\n",
    "labelEncode(data[\"BsmtFinType1\"], score_set)\n",
    "# HeatingQC\n",
    "score_set = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "labelEncode(data[\"HeatingQC\"], score_set)\n",
    "# KitchenQual\n",
    "score_set = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "labelEncode(data[\"KitchenQual\"], score_set)\n",
    "# Fireplace\n",
    "score_set = [\"NA\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "labelEncode(data[\"FireplaceQu\"], score_set)\n",
    "# GarageFinish\n",
    "score_set = [\"NA\", \"Unf\", \"RFn\", \"Fin\"]\n",
    "labelEncode(data[\"GarageFinish\"], score_set)\n",
    "\n",
    "print(data[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3 Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage      True\n",
      "LotArea         False\n",
      "LotShape        False\n",
      "Neighborhood    False\n",
      "HouseStyle      False\n",
      "OverallQual     False\n",
      "OverallCond     False\n",
      "YearBuilt       False\n",
      "YearRemodAdd    False\n",
      "MasVnrArea       True\n",
      "ExterQual       False\n",
      "BsmtQual        False\n",
      "BsmtExposure    False\n",
      "BsmtFinType1    False\n",
      "BsmtFinSF1      False\n",
      "BsmtUnfSF       False\n",
      "TotalBsmtSF     False\n",
      "HeatingQC       False\n",
      "1stFlrSF        False\n",
      "2ndFlrSF        False\n",
      "GrLivArea       False\n",
      "BsmtFullBath    False\n",
      "FullBath        False\n",
      "HalfBath        False\n",
      "BedroomAbvGr    False\n",
      "KitchenQual     False\n",
      "TotRmsAbvGrd    False\n",
      "Fireplaces      False\n",
      "FireplaceQu     False\n",
      "GarageType       True\n",
      "GarageFinish    False\n",
      "GarageCars      False\n",
      "GarageArea      False\n",
      "OpenPorchSF     False\n",
      "MoSold          False\n",
      "YrSold          False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Fill NA value\n",
    "print(data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "# NA Process\n",
    "# Feature LotFrontagee\n",
    "na_table = data[\"LotFrontage\"].isnull()\n",
    "# Use mean value to replace NA\n",
    "mean = np.mean(data[\"LotFrontage\"])\n",
    "for i in range(0, len(na_table)):\n",
    "    if na_table[i] == True:\n",
    "        data[\"LotFrontage\"][i] = mean\n",
    "# Feature MasVnrArea\n",
    "na_table = data[\"MasVnrArea\"].isnull()\n",
    "mean = np.mean(data[\"MasVnrArea\"])\n",
    "for i in range(0, len(na_table)):\n",
    "    if na_table[i] == True:\n",
    "        data[\"MasVnrArea\"][i] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Variable\n",
    "# GarageType\n",
    "na_table = data[\"GarageType\"].isnull()\n",
    "remainLevel = [\"Attchd\", \"Detchd\"]\n",
    "length = len(remainLevel)\n",
    "for i in range(0, len(data[\"GarageType\"])):\n",
    "    if na_table[i] == True:\n",
    "        data[\"GarageType\"][i] = \"NoGarage\"\n",
    "        continue\n",
    "    for j in range(0, length):\n",
    "        if data[\"GarageType\"][i] == remainLevel[j]:\n",
    "            break\n",
    "        if j == length - 1 and data[\"GarageType\"][i] != remainLevel[j]:\n",
    "            data[\"GarageType\"][i] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HouseStyle\n",
    "for i in range(0, len(data[\"HouseStyle\"])):\n",
    "    if data[\"HouseStyle\"][i] == \"1.5Fin\" or data[\"HouseStyle\"][i] == \"1.5Unf\":\n",
    "        data['HouseStyle'][i] = \"1.5Story\"\n",
    "        continue\n",
    "    if data[\"HouseStyle\"][i] == \"2.5Fin\" or data[\"HouseStyle\"][i] == \"2.5Unf\":\n",
    "        data[\"HouseStyle\"][i] = \"2.5Story\"\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Variable\n",
    "data = pd.get_dummies(data, columns=[\"Neighborhood\", \"GarageType\", \"HouseStyle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4519361  -0.09188637  0.70129102 -0.07183611  2.17962776  0.15673371\n",
      "  -0.42957697 -0.57441047 -0.68960393  0.58316783  2.22099903  0.69011514\n",
      "   1.17199212 -0.64122799  0.46646492  0.89117944  0.25714043 -0.79516323\n",
      "  -0.48251191 -0.81996437  0.78974052 -0.76162067  0.16377912 -0.77109084\n",
      "  -0.31868327  0.60049493  0.64889007  0.31847458  0.31172464 -0.06073101\n",
      "  -0.70448325 -0.48911005 -0.61443862 -0.10854037 -0.03703704 -0.10526316\n",
      "  -0.20339487 -0.1398323  -0.33838413 -0.19025216 -0.27116307 -0.23917551\n",
      "  -0.16124951 -0.10854037 -0.1863522  -0.42683279 -0.07875671 -0.22941573\n",
      "  -0.16998114 -0.23595776 -0.28963792 -0.13199092 -0.23106504 -0.20521398\n",
      "  -0.25018188 -0.13199092 -0.16347148 11.47725023  0.82350526 -0.60055892\n",
      "  -0.24235968 -0.3019617  -0.36059806  1.00549455 -0.11482721 -0.66213567\n",
      "  -0.16124951 -0.21585871]\n",
      " [-0.09311018  0.07347998 -1.01663664  0.65147924 -0.51719981  0.9847523\n",
      "   0.83021457  0.32306034  1.05230219  0.58316783  0.34662991  1.16471151\n",
      "   0.09290718 -0.30164298 -0.31336875  0.89117944 -0.62782603  1.18935062\n",
      "   0.51501256  1.10781015  0.78974052  1.22758538  0.16377912  0.73599434\n",
      "  -0.31868327  0.60049493  0.64889007  0.31847458  0.31172464  0.63172623\n",
      "  -0.07036146  0.99089135  0.13877749 -0.10854037 -0.03703704 -0.10526316\n",
      "  -0.20339487 -0.1398323   2.95522137 -0.19025216 -0.27116307 -0.23917551\n",
      "  -0.16124951 -0.10854037 -0.1863522  -0.42683279 -0.07875671 -0.22941573\n",
      "  -0.16998114 -0.23595776 -0.28963792 -0.13199092 -0.23106504 -0.20521398\n",
      "  -0.25018188 -0.13199092 -0.16347148 -0.08712888  0.82350526 -0.60055892\n",
      "  -0.24235968 -0.3019617  -0.36059806 -0.99453548 -0.11482721  1.51026451\n",
      "  -0.16124951 -0.21585871]\n",
      " [-0.45647437 -0.09689747 -1.01663664  0.65147924 -0.51719981 -1.86363165\n",
      "  -0.72029809 -0.57441047 -0.68960393 -0.55815259 -0.59055465  0.69011514\n",
      "  -0.49927358 -0.06166957 -0.68732408 -0.15138625 -0.52173356  0.93727612\n",
      "   0.38365915  1.10781015 -1.02604084 -0.76162067  0.16377912  0.73599434\n",
      "   0.29676325  0.60049493  1.20129794 -0.80194202  1.65030694  0.79080425\n",
      "  -0.17604842 -1.5991111  -1.36765473 -0.10854037 -0.03703704 -0.10526316\n",
      "  -0.20339487 -0.1398323  -0.33838413  5.25618217 -0.27116307 -0.23917551\n",
      "  -0.16124951 -0.10854037 -0.1863522  -0.42683279 -0.07875671 -0.22941573\n",
      "  -0.16998114 -0.23595776 -0.28963792 -0.13199092 -0.23106504 -0.20521398\n",
      "  -0.25018188 -0.13199092 -0.16347148 -0.08712888 -1.21432132  1.66511556\n",
      "  -0.24235968 -0.3019617  -0.36059806 -0.99453548 -0.11482721  1.51026451\n",
      "  -0.16124951 -0.21585871]\n",
      " [ 0.63361819  0.37514829 -1.01663664  1.3747946  -0.51719981  0.95163156\n",
      "   0.73330753  1.36456968  1.05230219  0.58316783  1.28381447  1.16471151\n",
      "   0.46356847 -0.17486457  0.19967971  0.89117944 -0.04561126  1.61787729\n",
      "   1.2993257   1.10781015  0.78974052  1.22758538  1.39002276  0.73599434\n",
      "   1.52765629  0.60049493  0.64889007  0.31847458  1.65030694  1.69848468\n",
      "   0.56376033  2.10089239  0.13877749 -0.10854037 -0.03703704 -0.10526316\n",
      "  -0.20339487 -0.1398323  -0.33838413 -0.19025216 -0.27116307 -0.23917551\n",
      "  -0.16124951 -0.10854037 -0.1863522  -0.42683279 -0.07875671 -0.22941573\n",
      "   5.8830057  -0.23595776 -0.28963792 -0.13199092 -0.23106504 -0.20521398\n",
      "  -0.25018188 -0.13199092 -0.16347148 -0.08712888  0.82350526 -0.60055892\n",
      "  -0.24235968 -0.3019617  -0.36059806 -0.99453548 -0.11482721  1.51026451\n",
      "  -0.16124951 -0.21585871]]\n"
     ]
    }
   ],
   "source": [
    "# Scale Data\n",
    "scaler = StandardScaler()\n",
    "scale_data = scaler.fit_transform(data)\n",
    "print(scale_data[1:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-4 Train Data with different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Linear Regression(Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14658811628248603\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "# Baseline Model (Linear Regression)\n",
    "model = LinearRegression()\n",
    "y_pred = cross_val_predict(model, scale_data, target, cv=10)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_pred, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "predictors = pd.read_csv('newtrain.csv')\n",
    "predictors = predictors.iloc[:,1:-1]\n",
    "target = pd.read_csv('target.csv',header=None)\n",
    "target = target.iloc[:,1]\n",
    "\n",
    "print(predictors.shape[0])\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14658605782219736"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg= LinearRegression().fit(predictors, target)\n",
    "target_predicted = cross_val_predict(linreg, predictors, target, cv=10)\n",
    "rmse(target,target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge & Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14658309093979632\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "## Ridge\n",
    "from sklearn.linear_model import Ridge \n",
    "\n",
    "best_rmse = 1\n",
    "for a in [0.0001,0.001,0.01,0.1,1,10,100,1000]:\n",
    "    RidgeModel=Ridge(alpha = a)\n",
    "    target_predicted = cross_val_predict(RidgeModel, predictors, target, cv=10)         \n",
    "    score = rmse(target,target_predicted)\n",
    "    \n",
    "    if score < best_rmse:\n",
    "        best_rmse = score\n",
    "        best_parameter = a\n",
    "\n",
    "print(best_rmse)\n",
    "print(best_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1468117255118387\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "best_rmse = 1\n",
    "for a in [0.0001,0.001,0.01,0.1,1,10,100,1000]:\n",
    "    LassoModel = Lasso(alpha = a)\n",
    "    target_predicted = cross_val_predict(LassoModel, predictors, target, cv=10)         \n",
    "    score = rmse(target,target_predicted)\n",
    "    \n",
    "    if score < best_rmse:\n",
    "        best_rmse = score\n",
    "        best_parameter = a\n",
    "\n",
    "print(best_rmse)\n",
    "print(best_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### knn regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22196999469826473\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "## knn regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "best_rmse = 1\n",
    "\n",
    "for n_neigh in [1,3,5,10]:\n",
    "    knnreg = KNeighborsRegressor(n_neighbors = n_neigh)\n",
    "    target_predicted = cross_val_predict(knnreg, predictors, target, cv=10)         \n",
    "    score = rmse(target,target_predicted)\n",
    "    \n",
    "    if score < best_rmse:\n",
    "        best_rmse = score\n",
    "        best_parameter = n_neigh\n",
    "\n",
    "print(best_rmse)\n",
    "print(best_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dtree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19763745470961303\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "## Dtree regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "best_rmse = 1\n",
    "\n",
    "for depth in [1,3,5,10,20,60]:\n",
    "    dtreereg = DecisionTreeRegressor(max_depth = depth)\n",
    "    target_predicted = cross_val_predict(dtreereg, predictors, target, cv=10)         \n",
    "    score = rmse(target,target_predicted)\n",
    "    \n",
    "    if score < best_rmse:\n",
    "        best_rmse = score\n",
    "        best_parameter = depth\n",
    "\n",
    "print(best_rmse)\n",
    "print(best_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15591714554189626"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Adaboost\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "adareg = AdaBoostRegressor(LinearRegression(),n_estimators=100, random_state=0)\n",
    "adareg.fit(predictors, target)\n",
    "target_predicted = cross_val_predict(adareg, predictors, target, cv=10)\n",
    "rmse(target,target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.589286735034715"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NN regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nnreg = MLPRegressor().fit(predictors, target)\n",
    "target_predicted = cross_val_predict(nnreg, predictors, target, cv=10)\n",
    "rmse(target,target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.013821308758544"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SVM regression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svmreg = MLPRegressor().fit(predictors, target)\n",
    "target_predicted = cross_val_predict(svmreg, predictors, target, cv=10)\n",
    "rmse(target,target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14221426306108007"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## randomforest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfreg = RandomForestRegressor(n_estimators=100,max_depth=50).fit(predictors, target)\n",
    "target_predicted = cross_val_predict(rfreg, predictors, target, cv=10)\n",
    "rmse(target,target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Conclusions\n",
    " \n",
    "Compared with different models, we find that randomforest has better performance than the others. But it can still imporve. Considering the model's parameters, we didn't get the best combination to predict th house pricing.There are two important limitations affecting the performance of our approach. \n",
    "<br><br>\n",
    "First limitation is related to the large number of features. It makes the performance of our model hard to improve. A solution to this issue is that we try to select features that are more related to the predictor and introduce some dummy variables, which helps a little to final results. \n",
    "<br><br>\n",
    "The second limitation is the ensemble methods. In this project, we do not find a good way to ensemble our models. We have learned that some ensemble methods such as stacking may work better in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reference\n",
    "\n",
    "[1] Bourassa, S. C., Cantoni, E., & Hoesli, M. (2007). Spatial dependence, housing submarkets, and house price prediction. The Journal of Real Estate Finance and Economics, 35(2), 143-160.\n",
    "\n",
    "[2] Lu, S., Li, Z., Qin, Z., Yang, X., & Goh, R. S. M. (2017, December). A hybrid regression technique for house prices prediction. In Industrial Engineering and Engineering Management (IEEM), 2017 IEEE International Conference on(pp. 319-323). IEEE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### responsibilities\n",
    "Shiqi Wang：feature expansion,feature selection,report writing\n",
    "\n",
    "Tao Tao: data preprocessing,feature selection,model training\n",
    "\n",
    "Ben Ying: data preprocessing,feature selection,model training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
